{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GxxuZFUd2wzW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias"
      ],
      "metadata": {
        "id": "O4kfyF09mUY7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_zgo6t6SfyYq"
      },
      "outputs": [],
      "source": [
        "# Referencia:\n",
        "# https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lib and data importing"
      ],
      "metadata": {
        "id": "c_A8EtejmXBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cg8lkocaf6SB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Datasets\n",
        "true = pd.read_csv('/content/drive/MyDrive/colab/True.csv')\n",
        "fake = pd.read_csv('/content/drive/MyDrive/colab/Fake.csv')"
      ],
      "metadata": {
        "id": "oiyov700hBmQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre analising"
      ],
      "metadata": {
        "id": "iwyIMMsPmcae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "true.shape , fake.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otdjRJ4Than0",
        "outputId": "7aebff11-342c-433c-c92d-7fe3f02d5117"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21417, 4), (23481, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(true)/(len(true)+len(fake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asTfRo6Ri3LZ",
        "outputId": "e181b84e-737a-414b-8baa-597708e1ab21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47701456635039424"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando diferentes subjects\n",
        "print('fake subjects= ', fake['subject'].unique())\n",
        "print('true subjects= ', true['subject'].unique())\n",
        "# Acredito que não fará diferença usar isto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMdBKsuZhHrd",
        "outputId": "bd974d3d-f748-4130-ebc5-a2f30cc7b174"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fake subjects=  ['News' 'politics' 'Government News' 'left-news' 'US_News' 'Middle-east']\n",
            "true subjects=  ['politicsNews' 'worldnews']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o Target\n",
        "fake = fake.assign(isfake=1)\n",
        "true = true.assign(isfake=0)\n",
        "\n",
        "# Juntando os dfs\n",
        "df = pd.concat([fake, true], ignore_index=True)"
      ],
      "metadata": {
        "id": "iIdSYFDUjmw5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para saber quantas datas são unicas.\n",
        "df['date'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTv9KssIi1_f",
        "outputId": "93620643-d9a6-44c4-ae42-97e01e5d214f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2397"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para saber quantos dados tem campos em branco.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4aJ_v67j4-B",
        "outputId": "a0199277-fba2-4725-956c-6fb1f4ca8acc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "title      0\n",
              "text       0\n",
              "subject    0\n",
              "date       0\n",
              "isfake     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo estas colunas, Se precisar rodo dnv com elas.\n",
        "df = df.drop(['date', 'subject'], axis=1)"
      ],
      "metadata": {
        "id": "kcZvEOf4h5DF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformando Texto"
      ],
      "metadata": {
        "id": "WNHnz-3moQGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Usando RoBERTa = tokenizer_roberta!"
      ],
      "metadata": {
        "id": "WM31peXPrHSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "\n",
        "# Carregar o tokenizer pré-treinado do modelo RoBERTa\n",
        "tokenizer_roberta = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Exemplo de uso do tokenizer\n",
        "text = \"Esta é uma frase de exemplo.\"\n",
        "tokens = tokenizer_roberta.tokenize(text)\n",
        "print(\"Tokens RoBERTa:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "836dETwmnhWn",
        "outputId": "5e184479-cb2f-407f-aec0-724324333852"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens RoBERTa: ['Est', 'a', 'ĠÃ©', 'Ġu', 'ma', 'Ġfr', 'ase', 'Ġde', 'Ġexempl', 'o', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso do tokenizer\n",
        "text = \"outro teste.\"\n",
        "tokens = tokenizer_roberta.tokenize(text)\n",
        "print(\"Tokens RoBERTa:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pboj9MeuqZX1",
        "outputId": "d778f4a1-e5c5-4d8b-ca19-0b454fdea793"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens RoBERTa: ['out', 'ro', 'Ġtest', 'e', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando GPT = tokenizer_gpt\n"
      ],
      "metadata": {
        "id": "QA7X4iGNrMFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Carregar o tokenizer pré-treinado do modelo GPT\n",
        "tokenizer_gpt = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Definir um token de padding\n",
        "tokenizer_gpt.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Exemplo de uso do tokenizer\n",
        "text = \"This is an example sentence.\"\n",
        "tokens = tokenizer_gpt.tokenize(text)\n",
        "print(\"Tokens GPT:\", tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txdK41wkqUNr",
        "outputId": "3aba357f-1a26-4569-a361-d397c6351e5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens GPT: ['This', 'Ġis', 'Ġan', 'Ġexample', 'Ġsentence', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso do tokenizer\n",
        "text = \"outro teste.\"\n",
        "tokens = tokenizer_gpt.tokenize(text)\n",
        "print(\"Tokens GPT:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs8G8IeEqfBl",
        "outputId": "5f8b5e40-00ec-47ab-f4ae-1671bb017c48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens GPT: ['out', 'ro', 'Ġtest', 'e', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading modelo"
      ],
      "metadata": {
        "id": "aV7RwzRzrBmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_gpt=100\n",
        "\n",
        "# Função para tokenizar texto usando o tokenizer\n",
        "def tokenize_text(text, tokenizer, max_length_gpt):\n",
        "    tokens = tokenizer(text, padding=True, truncation=True, max_length=max_length_gpt)\n",
        "    input_ids = tokens['input_ids']\n",
        "    attention_mask = tokens['attention_mask']\n",
        "    return input_ids#, attention_mask"
      ],
      "metadata": {
        "id": "WiAqcXPPrSKj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamanho do vocabulário\n",
        "vocab_size = len(tokenizer_gpt)\n",
        "print(\"Tamanho do vocabulário:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgG6ALovdCaf",
        "outputId": "3db91c86-d9c9-4069-8065-86bbbe0a2891"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do vocabulário: 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Explicaçãozinha:"
      ],
      "metadata": {
        "id": "GxxuZFUd2wzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um tokenizador é uma parte fundamental do processamento de linguagem natural (NLP). Sua função principal é transformar um texto em uma sequência de tokens, que são unidades menores de linguagem, como palavras, subpalavras, caracteres ou até mesmo partes de palavras. Aqui está uma explicação passo a passo de como um tokenizador opera:\n",
        "\n",
        "- **Divisão do texto em unidades menores:** O tokenizador recebe um texto como entrada e o divide em unidades menores, chamadas tokens. Esses tokens podem ser palavras individuais, partes de palavras, caracteres ou subpalavras, dependendo do tipo de tokenização usada e da linguagem específica.\n",
        "\n",
        "- **Remoção de espaços em branco e pontuação:** Em muitos casos, o tokenizador remove espaços em branco adicionais e pontuações do texto para simplificar o processo de tokenização. Isso ajuda a garantir que os tokens resultantes sejam unidades significativas de linguagem.\n",
        "\n",
        "- **Aplicação de regras de tokenização**: Dependendo da implementação específica do tokenizador e da língua, podem ser aplicadas várias regras de tokenização. Por exemplo, em inglês, as contrações como \"can't\" podem ser divididas em \"can\" e \"'t\", ou em algumas línguas, como o chinês, os tokens podem corresponder a caracteres individuais.\n",
        "\n",
        "- **Tratamento de casos especiais:** Alguns tokenizadores lidam com casos especiais, como números, datas ou entidades nomeadas, de maneira específica. Por exemplo, números podem ser representados como um token único ou divididos em dígitos individuais.\n",
        "\n",
        "- **Construção do vocabulário:** Durante o processo de tokenização, o tokenizador geralmente constrói um vocabulário que mapeia os tokens para índices numéricos. Isso é importante para representar o texto de entrada de uma maneira que um modelo de linguagem possa entender.\n",
        "\n",
        "- **Saída dos tokens**: O tokenizador produz uma sequência de tokens que representa o texto de entrada. Esses tokens podem então ser usados como entrada para modelos de linguagem, como redes neurais, para realizar tarefas como classificação de texto, geração de texto, tradução automática, entre outras.\n",
        "\n",
        "Em resumo, um tokenizador desempenha um papel fundamental no processamento de linguagem natural, transformando texto em uma representação numérica que os modelos de aprendizado de máquina podem entender e processar. Ele é uma etapa crucial em muitas aplicações de NLP.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:527/1*gWP5Whykah1101EpYy17qQ.png\" alt=\"descrição da imagem\">\n",
        "\n",
        "\n",
        "\n",
        "1. **Input IDs (`input_ids`)**:\n",
        "   - As 'input_ids' são uma sequência de números que representam cada token no texto após a tokenização.\n",
        "   - Cada token é mapeado para um ID numérico específico de acordo com o vocabulário do modelo.\n",
        "   - Esses IDs são o que o modelo de linguagem recebe como entrada durante o processo de treinamento ou inferência.\n",
        "   - Por exemplo, a palavra \"hello\" pode ser mapeada para o ID 101 no vocabulário do modelo.\n",
        "\n",
        "2. **Attention Mask (`attention_mask`)**:\n",
        "   - A 'attention_mask' é uma sequência binária que indica ao modelo quais tokens são de fato tokens de entrada e quais são tokens de preenchimento (padding).\n",
        "   - Os tokens de entrada recebem o valor 1, enquanto os tokens de preenchimento recebem o valor 0.\n",
        "   - Essa máscara permite que o modelo saiba quais tokens devem ser considerados durante o cálculo da atenção.\n",
        "\n",
        "Além desses, o tokenizer geralmente oferece outros atributos e métodos úteis, como:\n",
        "\n",
        "- **Token Type IDs**: Usado em modelos que lidam com pares de sequências, como BERT. Indica a que sequência pertence cada token (sequência A ou sequência B).\n",
        "- **Special Tokens**: Tokens especiais adicionados ao vocabulário do modelo, como tokens de início e fim de sequência, tokens de padding, tokens de separação de sequência, etc.\n",
        "- **Métodos de Tokenização**: Métodos para tokenizar texto, como `encode()` para converter texto em IDs de tokens, `decode()` para converter IDs de tokens de volta para texto, entre outros.\n",
        "- **Configurações e Parâmetros**: Opções para configurar o tokenizer, como tamanho máximo de sequência, adição de tokens especiais, etc.\n",
        "\n",
        "Esses são alguns dos principais componentes e funcionalidades encontradas em um tokenizer usado em modelos de linguagem como o GPT-2. Cada modelo e biblioteca pode ter variações em seus atributos e métodos específicos."
      ],
      "metadata": {
        "id": "CfWop49A2uMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizando"
      ],
      "metadata": {
        "id": "SLjcxDNg29qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando se a função funciona\n",
        "df_separado = df.iloc[[0,2]].copy()\n",
        "\n",
        "# Aplicar tqdm ao processar cada linha do DataFrame\n",
        "tqdm.pandas()\n",
        "\n",
        "# Aplicar a função de tokenização a cada linha do DataFrame\n",
        "df_separado['text'] = df_separado['text'].progress_apply(lambda x: tokenize_text(x,tokenizer_roberta,max_length_gpt))\n",
        "\n",
        "# Vendo se funcionou\n",
        "df_separado"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LQx3BfjqxDZN",
        "outputId": "396d2ae1-1ac5-4e46-ac2d-0712c03a38de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 42.04it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
              "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
              "\n",
              "                                                text  isfake  \n",
              "0  [0, 19195, 140, 95, 1705, 326, 2813, 70, 1791,...       1  \n",
              "2  [0, 4148, 273, 6, 24, 21, 1487, 14, 320, 5819,...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23145653-fd0c-478a-8490-522c54e0d4f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>isfake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>[0, 19195, 140, 95, 1705, 326, 2813, 70, 1791,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>[0, 4148, 273, 6, 24, 21, 1487, 14, 320, 5819,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23145653-fd0c-478a-8490-522c54e0d4f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23145653-fd0c-478a-8490-522c54e0d4f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23145653-fd0c-478a-8490-522c54e0d4f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5ac872a6-9b4b-47f8-844f-d4809dabdf3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ac872a6-9b4b-47f8-844f-d4809dabdf3c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5ac872a6-9b4b-47f8-844f-d4809dabdf3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7fe0a378-89c4-4daf-8653-11daf2782ab0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_separado')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7fe0a378-89c4-4daf-8653-11daf2782ab0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_separado');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_separado",
              "summary": "{\n  \"name\": \"df_separado\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \" Sheriff David Clarke Becomes An Internet Joke For Threatening To Poke People \\u2018In The Eye\\u2019\",\n          \" Donald Trump Sends Out Embarrassing New Year\\u2019s Eve Message; This is Disturbing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isfake\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df_separado.loc[0, 'text']\n",
        "len(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkq0wGZ26mxr",
        "outputId": "ca770d86-6563-45f1-d379-6991e404fd3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Atribuir os valores a uma variável\n",
        "valores = df_separado.loc[0, 'text']\n",
        "\n",
        "# Separar os valores individualmente\n",
        "primeira_lista = valores\n",
        "\n",
        "# Exibir os valores separados\n",
        "print(\"Primeira lista:\", primeira_lista)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXd5ERxh-LnY",
        "outputId": "63377e11-afd4-471a-b0f3-a0ee48686758"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeira lista: [0, 19195, 140, 95, 1705, 326, 2813, 70, 1791, 10, 9899, 188, 2041, 8, 989, 24, 23, 14, 4, 2978, 6, 37, 56, 7, 492, 10, 18066, 66, 7, 39, 11058, 6, 3988, 268, 8, 1437, 5, 182, 27820, 4486, 340, 433, 4, 1437, 20, 320, 2015, 311, 999, 56, 95, 65, 633, 7, 109, 8, 37, 1705, 326, 109, 24, 4, 287, 84, 5093, 6042, 11461, 3651, 8, 18369, 6, 38, 236, 7, 2813, 70, 9, 127, 964, 6, 2732, 6, 11058, 6, 3988, 268, 6, 8, 190, 5, 182, 27820, 24530, 491, 2454, 6, 10, 9899, 8, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar a função de tokenização a cada linha do DataFrame\n",
        "df_token = df.copy()\n",
        "\n",
        "# Aplicar tqdm ao processar cada linha do DataFrame\n",
        "tqdm.pandas()\n",
        "\n",
        "# Aplicar a função de tokenização a cada linha do DataFrame\n",
        "df_token['text'] = df_token['text'].progress_apply(lambda x: tokenize_text(x,tokenizer_roberta,max_length_gpt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I78h_0qSsJzT",
        "outputId": "3f151b2c-3b70-4f0a-e44e-334e9ca79ec6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44898/44898 [03:28<00:00, 215.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming, Cleaning and Spliting Data"
      ],
      "metadata": {
        "id": "ZnqPIeMdmLOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preparar(df_escolhido):\n",
        "    # Atribuir os valores a uma variável\n",
        "    valores = df_escolhido['text']\n",
        "\n",
        "    # Lista para armazenar os valores separados\n",
        "    lista_separada = []\n",
        "\n",
        "    # Loop através de cada linha do DataFrame\n",
        "    for linha in valores:\n",
        "        # Lista interna para armazenar os elementos individuais da linha\n",
        "        lista_1 = []\n",
        "\n",
        "        # Acessar a lista dentro da tupla\n",
        "        lista_individual = linha\n",
        "\n",
        "        # Adicionar os elementos de lista_individual a lista_1\n",
        "        lista_1.extend(lista_individual)\n",
        "\n",
        "        # Adicionar a lista interna à lista principal\n",
        "        lista_separada.append(lista_1)\n",
        "\n",
        "    # Converter lista_separada em DataFrame\n",
        "    df_final = pd.DataFrame(lista_separada)\n",
        "\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "KYt6JMuQgWci"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando os dados em features (X) e alvo (y)\n",
        "X = df_token[['text']]\n",
        "y = df_token['isfake']\n",
        "\n",
        "df_padded = preparar(X)\n",
        "\n",
        "df_padded['isfake'] = y"
      ],
      "metadata": {
        "id": "yFQ5UKaBgt-N"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liJSxIfHxXLO",
        "outputId": "34bb84bd-b5fd-4f2e-fdea-717616ec32cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44898, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded['isfake'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "440mA1827BxP",
        "outputId": "6bc2080e-8709-414c-dfd7-3552d56fd307"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isfake\n",
              "1    23481\n",
              "0    21417\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded = df_padded.dropna()"
      ],
      "metadata": {
        "id": "HB-gCqIVxPmJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded['isfake'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRb3Jrm6qlz",
        "outputId": "a5915b94-c346-412b-d089-605c4ef39696"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isfake\n",
              "1    21263\n",
              "0    19629\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxhz_f-O4ztp",
        "outputId": "bdb7a947-3e2e-4b33-89a9-503c01301e5f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "96        0\n",
              "97        0\n",
              "98        0\n",
              "99        0\n",
              "isfake    0\n",
              "Length: 101, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpchF_S-u4ri",
        "outputId": "da920a1a-2481-4036-9e0f-56d53bb59bce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40892, 101)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando os dados em features (X) e alvo (y)\n",
        "X = df_padded.drop(columns=['isfake'])\n",
        "y = df_padded['isfake']\n",
        "\n",
        "# Dividindo os dados em conjuntos de treinamento e teste (por exemplo, 80% treinamento, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Exibindo os tamanhos dos conjuntos de treinamento e teste\n",
        "print(\"Tamanho do conjunto de treinamento:\", len(X_train))\n",
        "print(\"Tamanho do conjunto de teste:\", len(X_test))\n",
        "print(\"contagem de true e fake no teste:\", y_train.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypznM03oyXIt",
        "outputId": "31d3edbb-e62d-4999-ab7a-c888dc8b2827"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do conjunto de treinamento: 32713\n",
            "Tamanho do conjunto de teste: 8179\n",
            "contagem de true e fake no teste: isfake\n",
            "1    17033\n",
            "0    15680\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NeuralNetwork"
      ],
      "metadata": {
        "id": "DEu5xCxVyn9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random"
      ],
      "metadata": {
        "id": "-FYTUEbGe5FJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo DataFrame para numpy array\n",
        "X_train_padded_np = X_train.values\n",
        "\n",
        "# Converta X_train_padded para um tensor PyTorch com o mesmo tipo de dados dos parâmetros do modelo\n",
        "X_train_padded_tensor = torch.tensor(X_train_padded_np, dtype=torch.float)\n",
        "\n",
        "# Verifique o tipo de dados e o dispositivo do tensor\n",
        "print(\"Tipo de dados:\", X_train_padded_tensor.dtype)\n",
        "print(\"Dispositivo:\", X_train_padded_tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80WGXliJhZeU",
        "outputId": "14709b9c-d2bc-4eae-e84e-dc0963cb2cf2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dados: torch.float32\n",
            "Dispositivo: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZH6hYw9jaGX",
        "outputId": "3945e763-749d-405d-aa74-12c4f3eb4e8c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32713, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_lin(nn.Module):\n",
        "    def __init__(self, entrada_dim, output_dim):\n",
        "        super(Model_lin, self).__init__()\n",
        "        self.camada_entrada = nn.Linear(entrada_dim, 50)\n",
        "        self.camada_oculta = nn.Linear(50, 25)\n",
        "        self.camada_saida = nn.Linear(25, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.camada_entrada(x))\n",
        "        x = torch.relu(self.camada_oculta(x))\n",
        "        outputmodelo = torch.sigmoid(self.camada_saida(x))\n",
        "        return outputmodelo"
      ],
      "metadata": {
        "id": "4dOSLMxKe5sm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converta y_train para um tensor PyTorch\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "# Verifique novamente a forma da saída e dos rótulos verdadeiros\n",
        "print(\"Forma de X_train_padded_tensor:\", X_train_padded_tensor.shape)\n",
        "print(\"Forma de y_train_tensor:\", y_train_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNKjXN90lpmm",
        "outputId": "c820a1c1-a27c-447e-e389-e2e728bbd23b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de X_train_padded_tensor: torch.Size([32713, 100])\n",
            "Forma de y_train_tensor: torch.Size([32713, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded_tensor.type(), y_train_tensor.type()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_inFh0bKnBpG",
        "outputId": "66700c29-2322-4d09-9fa5-81abf1882ffa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('torch.FloatTensor', 'torch.FloatTensor')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo DataFrame para numpy array\n",
        "X_test_padded_np = X_test.values\n",
        "\n",
        "# Converta X_train_padded para um tensor PyTorch com o mesmo tipo de dados dos parâmetros do modelo\n",
        "X_test_padded_tensor = torch.tensor(X_test_padded_np, dtype=torch.float)\n",
        "\n",
        "# Converta y_train para um tensor PyTorch\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float).view(-1, 1)"
      ],
      "metadata": {
        "id": "z2sJV1dH2AKG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicialize o modelo\n",
        "modelo = Model_lin(entrada_dim=max_length_gpt, output_dim=1)\n",
        "\n",
        "# Defina a função de perda\n",
        "lossfn = nn.BCELoss()\n",
        "\n",
        "# Defina o otimizador\n",
        "otimizador = optim.Adam(modelo.parameters(), lr=0.001)\n",
        "\n",
        "# Número de épocas\n",
        "num_epochs = 100\n",
        "\n",
        "modelo.train()\n",
        "# Loop de treinamento\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    # Forward pass: Calcular a previsão (forward) do modelo\n",
        "    output = modelo(X_train_padded_tensor)\n",
        "\n",
        "    # Calcular a perda\n",
        "    loss = lossfn(output, y_train_tensor)\n",
        "\n",
        "    # Backward pass: Calcula o gradiente da perda em relação aos parâmetros do modelo\n",
        "    otimizador.zero_grad()  # Zera os gradientes acumulados\n",
        "    loss.backward()  # Calcula os gradientes\n",
        "    otimizador.step()  # Atualiza os parâmetros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlsXakWffZs2",
        "outputId": "47014617-9cd1-4197-8949-58c2104008e8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ative o modo de avaliação\n",
        "modelo.eval()\n",
        "\n",
        "# Faça previsões nos dados de teste\n",
        "with torch.no_grad():\n",
        "    outputs = modelo(X_test_padded_tensor)\n",
        "    predicted_classes = (outputs > 0.5).float()  # Converta as previsões em classes binárias (0 ou 1)\n",
        "\n",
        "# Calcule a precisão\n",
        "accuracy = (predicted_classes == y_test_tensor).float().mean()\n",
        "print(f'Acurácia: {accuracy.item()*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojs14ng415P3",
        "outputId": "8539ae7e-85c6-46c5-9532-6b87fcee0bb0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 51.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForest"
      ],
      "metadata": {
        "id": "P_r4Sjdj4m4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Inicialize o modelo Random Forest\n",
        "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)  # Você pode ajustar o número de árvores (n_estimators) conforme necessário\n",
        "\n",
        "# Treine o modelo\n",
        "modelo_rf.fit(X_train, y_train)\n",
        "\n",
        "# Faça previsões nos dados de teste\n",
        "previsoes_rf = modelo_rf.predict(X_test)\n",
        "\n",
        "# Calcule a precisão\n",
        "acuracia_rf = accuracy_score(y_test, previsoes_rf)\n",
        "print(f'Acurácia do Random Forest: {acuracia_rf * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DNBmFmMVfA7",
        "outputId": "48464386-5ccd-4db2-d32e-5203eb8f4816"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Random Forest: 98.18%\n"
          ]
        }
      ]
    }
  ]
}